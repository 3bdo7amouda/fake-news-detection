{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6346c811",
   "metadata": {},
   "source": [
    "# Fake News Detection - Data Analysis & Model Training\n",
    "\n",
    "This notebook provides comprehensive analysis of the fake news detection project, including:\n",
    "- Data exploration and visualization\n",
    "- Model training and evaluation\n",
    "- Performance comparison\n",
    "- Interactive testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8001da5",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32925b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import our modules\n",
    "from src.data_preprocessing import DataPreprocessor\n",
    "from src.model_training import ModelTrainer\n",
    "from src.prediction import FakeNewsDetector, ModelComparator\n",
    "from src.utils import Config, create_directories\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create directories\n",
    "create_directories()\n",
    "\n",
    "print(\"✅ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f81d10",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72b2a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "# Load data (using sample data for demonstration)\n",
    "df = preprocessor.get_sample_data()\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040f665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Label distribution\n",
    "label_counts = df['label'].value_counts()\n",
    "axes[0].bar(['Fake', 'Real'], [label_counts[0], label_counts[1]], color=['red', 'green'])\n",
    "axes[0].set_title('Label Distribution')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Subject distribution\n",
    "subject_counts = df['subject'].value_counts()\n",
    "axes[1].bar(subject_counts.index, subject_counts.values)\n",
    "axes[1].set_title('Subject Distribution')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Real news: {label_counts[1]} articles\")\n",
    "print(f\"Fake news: {label_counts[0]} articles\")\n",
    "print(f\"Balance ratio: {label_counts[1]/label_counts[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e692d258",
   "metadata": {},
   "source": [
    "## 3. Text Analysis and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f56531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "df_processed = preprocessor.prepare_dataset(df)\n",
    "\n",
    "print(f\"Processed dataset shape: {df_processed.shape}\")\n",
    "print(f\"\\nProcessed text examples:\")\n",
    "for i, row in df_processed.head(3).iterrows():\n",
    "    print(f\"\\nOriginal: {row['combined_text'][:100]}...\")\n",
    "    print(f\"Processed: {row['processed_text'][:100]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25d0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text length analysis\n",
    "df_processed['text_length'] = df_processed['processed_text'].str.len()\n",
    "df_processed['word_count'] = df_processed['processed_text'].str.split().str.len()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Text length distribution\n",
    "axes[0, 0].hist(df_processed['text_length'], bins=20, alpha=0.7, color='skyblue')\n",
    "axes[0, 0].set_title('Text Length Distribution')\n",
    "axes[0, 0].set_xlabel('Characters')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Word count distribution\n",
    "axes[0, 1].hist(df_processed['word_count'], bins=20, alpha=0.7, color='lightgreen')\n",
    "axes[0, 1].set_title('Word Count Distribution')\n",
    "axes[0, 1].set_xlabel('Words')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Text length by label\n",
    "real_lengths = df_processed[df_processed['label'] == 1]['text_length']\n",
    "fake_lengths = df_processed[df_processed['label'] == 0]['text_length']\n",
    "\n",
    "axes[1, 0].hist([real_lengths, fake_lengths], bins=15, alpha=0.7, \n",
    "                label=['Real', 'Fake'], color=['green', 'red'])\n",
    "axes[1, 0].set_title('Text Length by Label')\n",
    "axes[1, 0].set_xlabel('Characters')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Word count by label\n",
    "real_words = df_processed[df_processed['label'] == 1]['word_count']\n",
    "fake_words = df_processed[df_processed['label'] == 0]['word_count']\n",
    "\n",
    "axes[1, 1].hist([real_words, fake_words], bins=15, alpha=0.7, \n",
    "                label=['Real', 'Fake'], color=['green', 'red'])\n",
    "axes[1, 1].set_title('Word Count by Label')\n",
    "axes[1, 1].set_xlabel('Words')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79247cf",
   "metadata": {},
   "source": [
    "## 4. Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa04cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word clouds for real and fake news\n",
    "real_text = ' '.join(df_processed[df_processed['label'] == 1]['processed_text'])\n",
    "fake_text = ' '.join(df_processed[df_processed['label'] == 0]['processed_text'])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Real news word cloud\n",
    "wordcloud_real = WordCloud(width=800, height=400, background_color='white').generate(real_text)\n",
    "axes[0].imshow(wordcloud_real, interpolation='bilinear')\n",
    "axes[0].set_title('Real News Word Cloud', fontsize=16)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Fake news word cloud\n",
    "wordcloud_fake = WordCloud(width=800, height=400, background_color='white').generate(fake_text)\n",
    "axes[1].imshow(wordcloud_fake, interpolation='bilinear')\n",
    "axes[1].set_title('Fake News Word Cloud', fontsize=16)\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e188ddc8",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model trainer\n",
    "trainer = ModelTrainer()\n",
    "\n",
    "# Train models using the full pipeline\n",
    "print(\"🤖 Starting model training...\")\n",
    "results = trainer.train_full_pipeline()\n",
    "\n",
    "print(f\"\\n✅ Training completed!\")\n",
    "print(f\"Best model: {results['best_model']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model performance comparison\n",
    "performance_df = pd.DataFrame(trainer.model_performances).T\n",
    "performance_df = performance_df.round(4)\n",
    "\n",
    "print(\"📊 Model Performance Comparison:\")\n",
    "print(performance_df)\n",
    "\n",
    "# Visualize performance metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "colors = ['skyblue', 'lightgreen', 'lightcoral', 'lightyellow']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i//2, i%2]\n",
    "    bars = ax.bar(performance_df.index, performance_df[metric], color=colors[i])\n",
    "    ax.set_title(f'{metric.replace(\"_\", \" \").title()}')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "               f'{height:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interactive Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test examples with different models\n",
    "test_examples = [\n",
    "    {\n",
    "        'title': 'Scientists Discover New Treatment for Cancer',\n",
    "        'text': 'Researchers at a major university have developed a promising new treatment for cancer that shows significant results in clinical trials.',\n",
    "        'expected': 'REAL'\n",
    "    },\n",
    "    {\n",
    "        'title': 'SHOCKING: Aliens Found in Government Facility',\n",
    "        'text': 'Government officials deny but sources confirm that extraterrestrial beings are being held at a secret facility.',\n",
    "        'expected': 'FAKE'\n",
    "    },\n",
    "    {\n",
    "        'title': 'Miracle Cure Discovered by Local Mom',\n",
    "        'text': 'Local mother discovers amazing cure that doctors hate using this one simple trick from her kitchen.',\n",
    "        'expected': 'FAKE'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Initialize detector with best model\n",
    "best_model_name, _ = trainer.get_best_model()\n",
    "detector = FakeNewsDetector(best_model_name)\n",
    "\n",
    "print(f\"🔍 Testing with best model: {best_model_name}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, example in enumerate(test_examples, 1):\n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(f\"Title: {example['title']}\")\n",
    "    print(f\"Expected: {example['expected']}\")\n",
    "    \n",
    "    result = detector.predict(example['text'], example['title'])\n",
    "    \n",
    "    status = \"REAL\" if result['is_real'] else \"FAKE\"\n",
    "    confidence = result['confidence']\n",
    "    \n",
    "    print(f\"Predicted: {status} ({confidence}% confidence)\")\n",
    "    print(f\"✅ Correct!\" if status == example['expected'] else \"❌ Incorrect!\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
